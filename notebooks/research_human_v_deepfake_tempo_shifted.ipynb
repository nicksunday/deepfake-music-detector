{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install pandas numpy matplotlib sklearn tensorflow torchvision pytorch opencv-python\n",
    "\n",
    "! export MallocStackLoggingNoCompact=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "# path_imgs = Path('./BinaryClassifiedSpectrograms/')\n",
    "# path_imgs1 = Path('./PitchShiftedBinaryClassifiedSpectrograms/')\n",
    "path_imgs = Path('./TempoShiftedBinaryClassifiedSpectrograms/')\n",
    "\n",
    "batch_size = 32\n",
    "# batch_size = 538\n",
    "\n",
    "hop_length = 512\n",
    "\n",
    "n_fft = 2048\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define Tranforms\n",
    "train_transforms = transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Resnet18_Weights.DEFAULT mean and std\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # Resnet18_Weights.DEFAULT mean and std\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the data\n",
    "# dataset = datasets.ImageFolder(path_imgs, transform = train_transforms)\n",
    "train_dataset = datasets.ImageFolder(path_imgs, transform = train_transforms)\n",
    "val_dataset = datasets.ImageFolder(path_imgs, transform = test_transforms)\n",
    "test_dataset = datasets.ImageFolder(path_imgs, transform = test_transforms)\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_train_samples = len(train_dataset)\n",
    "# num_train_samples = 5000\n",
    "\n",
    "# Permute the data\n",
    "indices = torch.randperm(num_train_samples)\n",
    "\n",
    "# Split the data into Train and Validation\n",
    "train_testval_split = 0.2\n",
    "train_split = int(num_train_samples * train_testval_split)\n",
    "val_split = int(train_split * 0.5)\n",
    "\n",
    "train_subset = torch.utils.data.Subset(train_dataset, indices[train_split:])\n",
    "val_subset = torch.utils.data.Subset(val_dataset, indices[val_split:train_split])\n",
    "test_subset = torch.utils.data.Subset(test_dataset, indices[:val_split])\n",
    "\n",
    "print(f\"Length of Train:{len(train_subset)}; Length of Val:{len(val_subset)}; Length of Test:{len(test_subset)}\")\n",
    "\n",
    "# Make DataLoaders \n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_subset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=val_subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Classes\n",
    "classes = train_dataloader.dataset.dataset.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataloader.dataset.dataset.classes)\n",
    "\n",
    "unique, counts = np.unique(train_dataloader.dataset.dataset.targets, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(train_dataloader.dataset.dataset.targets, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataloader.dataset.dataset.classes)\n",
    "print(train_dataloader.dataset.dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imgs, labels) = next(iter(train_dataloader))\n",
    "print(imgs.shape)\n",
    "print(labels.shape)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "if debug:\n",
    "    train_labels = set()\n",
    "    for (img, label) in train_subset:\n",
    "        train_labels.add(label)\n",
    "    print(f\"train_labels: {train_labels}\")\n",
    "    val_labels = set()\n",
    "    for (img, label) in val_subset:\n",
    "        val_labels.add(label)\n",
    "    print(f\"val_labels: {val_labels}\")\n",
    "    test_labels = set()\n",
    "    for (img, label) in test_subset:\n",
    "        test_labels.add(label)\n",
    "    print(f\"test_labels: {test_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(loader):\n",
    "    images, lebels = next(iter(loader))\n",
    "    # shape of images = [b,c,w,h]\n",
    "    mean, std = images.mean([0,2,3]), images.std([0,2,3])\n",
    "    return mean, std\n",
    "\n",
    "mean, std = mean_std(train_dataloader)\n",
    "print(\"mean and std: \\n\", mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Pretrained Model\n",
    "resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Fix the trainable parameters\n",
    "for parameter in resnet.parameters():\n",
    "    parameter.requires_grad = False\n",
    "    \n",
    "    \n",
    "# Number of Input Features in the Last Fully Connected Layer\n",
    "in_features = resnet.fc.in_features\n",
    "\n",
    "# Replacing the Last Fully Connected Layer\n",
    "fc = nn.Linear(in_features=in_features, out_features=len(classes))\n",
    "# fc = nn.Linear(in_features=in_features, out_features=2)\n",
    "resnet.fc = fc\n",
    "\n",
    "\n",
    "# Updating the Weights and Bias of the last layer\n",
    "params_to_update = []\n",
    "for name, param in resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "# Define the Loss and Optimizer Functions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_dataloader, test_dataloader, print_every,num_epoch):\n",
    "    \n",
    "    steps = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        running_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        start_time = time()\n",
    "        iter_time = time()\n",
    "        \n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            steps += 1\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # labels = torch.nn.functional.one_hot(labels)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            correct_train += (torch.max(output, dim=1)[1] == labels).sum()\n",
    "            total_train += labels.size(0)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Logging\n",
    "            if steps % print_every == 0:\n",
    "                print(f'Epoch [{epoch + 1}]/[{num_epoch}]. Batch [{i + 1}]/[{len(train_dataloader)}].', end=' ')\n",
    "                print(f'Train loss {running_loss / steps:.3f}.', end=' ')\n",
    "                print(f'Train acc {correct_train / total_train * 100:.3f}.', end=' ')\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    correct_val, total_val = 0, 0\n",
    "                    val_loss = 0\n",
    "                    for images, labels in test_dataloader:\n",
    "                        images = images.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        output = model(images)\n",
    "                        loss = criterion(output, labels)\n",
    "                        val_loss += loss.item()\n",
    "                        \n",
    "                        correct_val += (torch.max(output, dim=1)[1] == labels).sum()\n",
    "                        total_val += labels.size(0)\n",
    "\n",
    "                print(f'Val loss {val_loss / len(test_dataloader):.3f}. Val acc {correct_val / total_val * 100:.3f}.', end=' ')\n",
    "                print(f'Took {time() - iter_time:.3f} seconds')\n",
    "                iter_time = time()\n",
    "                \n",
    "                \n",
    "                train_losses.append(running_loss / total_train)\n",
    "                val_losses.append(val_loss / total_val)\n",
    "\n",
    "\n",
    "        print(f'Epoch took {time() - start_time}') \n",
    "        torch.save(model, f'checkpoint_{correct_val / total_val * 100:.2f}')\n",
    "        \n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 25\n",
    "num_epoch = 20\n",
    "\n",
    "resnet, train_losses, val_losses = train(\n",
    "    model=resnet,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=val_dataloader,\n",
    "    print_every=print_every,\n",
    "    num_epoch=num_epoch\n",
    ")\n",
    "\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = [\"deepfake\", \"human\"]\n",
    "\n",
    "y_test = []\n",
    "y_pred = []\n",
    "for img, label in test_subset:\n",
    "    img = torch.Tensor(img)\n",
    "    img = img.to(device)\n",
    "    resnet.eval()\n",
    "    prediction = resnet(img[None])\n",
    "    \n",
    "    final_pred = classes[torch.max(prediction, dim=1)[1]]\n",
    "    # final_pred = torch.max(prediction, dim=1)[1]\n",
    "\n",
    "    print(classes[label], final_pred)\n",
    "    \n",
    "    y_test.append(classes[label])\n",
    "    y_pred.append(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",(100*(np.array(y_test) == np.array(y_pred)).sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_pred, pos_label=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=classes)#[\"deepfake\", \"human\"])\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "#cmd = ConfusionMatrixDisplay(cm, display_labels=classes)#[\"deepfake\", \"human\"])\n",
    "#cmd.plot()\n",
    "#plt.show()\n",
    "\n",
    "print(\"True Negative: \", tn, end= '\\t|\\t')\n",
    "print(\"False Positive: \", fp)\n",
    "print(\"-\" * 55)\n",
    "print(\"False Negative: \", fn, end='\\t|\\t')\n",
    "print(\"True Positive: \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = tp / (tp + fn)\n",
    "FPR = fp / (fp + tn)\n",
    "PPV = tp / (tp + fp)\n",
    "Specificity = tn / (fp + tn)\n",
    "\n",
    "print(TPR) # True Positive Rate / recall / sensitivity\n",
    "print(FPR) # False Positive Rate / fall-out\n",
    "print(PPV) # Positive Predictive Value / Precision\n",
    "print(Specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
