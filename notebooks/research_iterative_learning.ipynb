{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "path_imgs1 = Path('./BinaryClassifiedSpectrograms/')\n",
    "path_imgs2 = Path('./PitchShiftedBinaryClassifiedSpectrograms/')\n",
    "path_imgs3 = Path('./TempoShiftedBinaryClassifiedSpectrograms/')\n",
    "path_imgs4 = Path('./TempoAndPitchShiftedBinaryClassifiedSpectrograms/')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "hop_length = 512\n",
    "\n",
    "n_fft = 2048\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define Tranforms\n",
    "train_transforms = transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Resnet18_Weights.DEFAULT mean and std\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # Resnet18_Weights.DEFAULT mean and std\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the data\n",
    "# dataset = datasets.ImageFolder(path_imgs, transform = train_transforms)\n",
    "train_dataset1 = datasets.ImageFolder(path_imgs1, transform = train_transforms)\n",
    "val_dataset1 = datasets.ImageFolder(path_imgs1, transform = test_transforms)\n",
    "test_dataset1 = datasets.ImageFolder(path_imgs1, transform = test_transforms)\n",
    "\n",
    "train_dataset2 = datasets.ImageFolder(path_imgs2, transform = train_transforms)\n",
    "val_dataset2 = datasets.ImageFolder(path_imgs2, transform = test_transforms)\n",
    "test_dataset2 = datasets.ImageFolder(path_imgs2, transform = test_transforms)\n",
    "\n",
    "train_dataset3 = datasets.ImageFolder(path_imgs3, transform = train_transforms)\n",
    "val_dataset3 = datasets.ImageFolder(path_imgs3, transform = test_transforms)\n",
    "test_dataset3 = datasets.ImageFolder(path_imgs3, transform = test_transforms)\n",
    "\n",
    "train_dataset4 = datasets.ImageFolder(path_imgs4, transform = train_transforms)\n",
    "val_dataset4 = datasets.ImageFolder(path_imgs4, transform = test_transforms)\n",
    "test_dataset4 = datasets.ImageFolder(path_imgs4, transform = test_transforms)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_train_samples1 = len(train_dataset1)\n",
    "num_train_samples2 = len(train_dataset2)\n",
    "num_train_samples3 = len(train_dataset3)\n",
    "num_train_samples4 = len(train_dataset4)\n",
    "# num_train_samples = 5000\n",
    "\n",
    "# Permute the data\n",
    "indices1 = torch.randperm(num_train_samples1)\n",
    "indices2 = torch.randperm(num_train_samples2)\n",
    "indices3 = torch.randperm(num_train_samples3)\n",
    "indices4 = torch.randperm(num_train_samples4)\n",
    "\n",
    "# Split the data into Train and Validation\n",
    "train_testval_split = 0.2\n",
    "train_split1 = int(num_train_samples1 * train_testval_split)\n",
    "val_split1 = int(train_split1 * 0.5)\n",
    "train_split2 = int(num_train_samples2 * train_testval_split)\n",
    "val_split2 = int(train_split2 * 0.5)\n",
    "train_split3 = int(num_train_samples3 * train_testval_split)\n",
    "val_split3 = int(train_split3 * 0.5)\n",
    "train_split4 = int(num_train_samples4 * train_testval_split)\n",
    "val_split4 = int(train_split4 * 0.5)\n",
    "\n",
    "train_subset1 = torch.utils.data.Subset(train_dataset1, indices1[train_split1:])\n",
    "val_subset1 = torch.utils.data.Subset(val_dataset1, indices1[val_split1:train_split1])\n",
    "test_subset1 = torch.utils.data.Subset(test_dataset1, indices1[:val_split1])\n",
    "train_subset2 = torch.utils.data.Subset(train_dataset2, indices2[train_split2:])\n",
    "val_subset2 = torch.utils.data.Subset(val_dataset2, indices2[val_split2:train_split2])\n",
    "test_subset2 = torch.utils.data.Subset(test_dataset2, indices2[:val_split2])\n",
    "train_subset3 = torch.utils.data.Subset(train_dataset3, indices3[train_split3:])\n",
    "val_subset3 = torch.utils.data.Subset(val_dataset3, indices3[val_split3:train_split3])\n",
    "test_subset3 = torch.utils.data.Subset(test_dataset3, indices3[:val_split3])\n",
    "train_subset4 = torch.utils.data.Subset(train_dataset4, indices4[train_split4:])\n",
    "val_subset4 = torch.utils.data.Subset(val_dataset4, indices4[val_split4:train_split4])\n",
    "test_subset4 = torch.utils.data.Subset(test_dataset4, indices4[:val_split4])\n",
    "\n",
    "print(f\"Length of Train1:{len(train_subset1)}; Length of Val:{len(val_subset1)}; Length of Test:{len(test_subset1)}\")\n",
    "print(f\"Length of Train2:{len(train_subset2)}; Length of Val:{len(val_subset2)}; Length of Test:{len(test_subset2)}\")\n",
    "print(f\"Length of Train3:{len(train_subset3)}; Length of Val:{len(val_subset3)}; Length of Test:{len(test_subset3)}\")\n",
    "print(f\"Length of Train4:{len(train_subset4)}; Length of Val:{len(val_subset4)}; Length of Test:{len(test_subset4)}\")\n",
    "\n",
    "# Make DataLoaders \n",
    "train_dataloader1 = torch.utils.data.DataLoader(\n",
    "    dataset=train_subset1, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader1 = torch.utils.data.DataLoader(\n",
    "    dataset=val_subset1,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_dataloader2 = torch.utils.data.DataLoader(\n",
    "    dataset=train_subset2, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader2 = torch.utils.data.DataLoader(\n",
    "    dataset=val_subset2,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_dataloader3 = torch.utils.data.DataLoader(\n",
    "    dataset=train_subset3, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader3 = torch.utils.data.DataLoader(\n",
    "    dataset=val_subset3,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_dataloader4 = torch.utils.data.DataLoader(\n",
    "    dataset=train_subset4, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader4 = torch.utils.data.DataLoader(\n",
    "    dataset=val_subset4,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Classes\n",
    "classes1 = train_dataloader1.dataset.dataset.classes\n",
    "classes2 = train_dataloader2.dataset.dataset.classes\n",
    "classes3 = train_dataloader3.dataset.dataset.classes\n",
    "classes4 = train_dataloader4.dataset.dataset.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Pretrained Model\n",
    "resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Fix the trainable parameters\n",
    "for parameter in resnet.parameters():\n",
    "    parameter.requires_grad = False\n",
    "    \n",
    "    \n",
    "# Number of Input Features in the Last Fully Connected Layer\n",
    "in_features = resnet.fc.in_features\n",
    "\n",
    "# Replacing the Last Fully Connected Layer\n",
    "fc = nn.Linear(in_features=in_features, out_features=len(classes2))\n",
    "# fc = nn.Linear(in_features=in_features, out_features=2)\n",
    "resnet.fc = fc\n",
    "\n",
    "\n",
    "# Updating the Weights and Bias of the last layer\n",
    "params_to_update = []\n",
    "for name, param in resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "# Define the Loss and Optimizer Functions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_dataloader, test_dataloader, print_every,num_epoch):\n",
    "    \n",
    "    steps = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        running_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        start_time = time()\n",
    "        iter_time = time()\n",
    "        \n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            steps += 1\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # labels = torch.nn.functional.one_hot(labels)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            correct_train += (torch.max(output, dim=1)[1] == labels).sum()\n",
    "            total_train += labels.size(0)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Logging\n",
    "            if steps % print_every == 0:\n",
    "                print(f'Epoch [{epoch + 1}]/[{num_epoch}]. Batch [{i + 1}]/[{len(train_dataloader)}].', end=' ')\n",
    "                print(f'Train loss {running_loss / steps:.3f}.', end=' ')\n",
    "                print(f'Train acc {correct_train / total_train * 100:.3f}.', end=' ')\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    correct_val, total_val = 0, 0\n",
    "                    val_loss = 0\n",
    "                    for images, labels in test_dataloader:\n",
    "                        images = images.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        output = model(images)\n",
    "                        loss = criterion(output, labels)\n",
    "                        val_loss += loss.item()\n",
    "                        \n",
    "                        correct_val += (torch.max(output, dim=1)[1] == labels).sum()\n",
    "                        total_val += labels.size(0)\n",
    "\n",
    "                print(f'Val loss {val_loss / len(test_dataloader):.3f}. Val acc {correct_val / total_val * 100:.3f}.', end=' ')\n",
    "                print(f'Took {time() - iter_time:.3f} seconds')\n",
    "                iter_time = time()\n",
    "                \n",
    "                \n",
    "                train_losses.append(running_loss / total_train)\n",
    "                val_losses.append(val_loss / total_val)\n",
    "\n",
    "\n",
    "        print(f'Epoch took {time() - start_time}') \n",
    "        torch.save(model, f'base_checkpoint_{correct_val / total_val * 100:.2f}')\n",
    "        \n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.load_state_dict(torch.load('base_final_state_dict', weights_only=True))\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 25\n",
    "num_epoch = 20\n",
    "\n",
    "resnet, train_losses2, val_losses2 = train(\n",
    "    model=resnet,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader2,\n",
    "    test_dataloader=val_dataloader2,\n",
    "    print_every=print_every,\n",
    "    num_epoch=num_epoch\n",
    ")\n",
    "\n",
    "\n",
    "plt.plot(train_losses2, label='Training loss')\n",
    "plt.plot(val_losses2, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'pitch_shifted_final_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.load_state_dict(torch.load('pitch_shifted_final_state_dict', weights_only=True))\n",
    "resnet.eval()\n",
    "\n",
    "# Fix the trainable parameters\n",
    "for parameter in resnet.parameters():\n",
    "    parameter.requires_grad = False\n",
    "    \n",
    "    \n",
    "# Number of Input Features in the Last Fully Connected Layer\n",
    "in_features = resnet.fc.in_features\n",
    "\n",
    "# Replacing the Last Fully Connected Layer\n",
    "fc = nn.Linear(in_features=in_features, out_features=len(classes3))\n",
    "# fc = nn.Linear(in_features=in_features, out_features=1)\n",
    "resnet.fc = fc\n",
    "\n",
    "\n",
    "# Updating the Weights and Bias of the last layer\n",
    "params_to_update = []\n",
    "for name, param in resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 25\n",
    "num_epoch = 20\n",
    "\n",
    "resnet, train_losses2, val_losses2 = train(\n",
    "    model=resnet,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader3,\n",
    "    test_dataloader=val_dataloader3,\n",
    "    print_every=print_every,\n",
    "    num_epoch=num_epoch\n",
    ")\n",
    "\n",
    "\n",
    "plt.plot(train_losses3, label='Training loss')\n",
    "plt.plot(val_losses3, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'tempo_shifted_final_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.load_state_dict(torch.load('tempo_shifted_final_state_dict', weights_only=True))\n",
    "resnet.eval()\n",
    "\n",
    "# Fix the trainable parameters\n",
    "for parameter in resnet.parameters():\n",
    "    parameter.requires_grad = False\n",
    "    \n",
    "    \n",
    "# Number of Input Features in the Last Fully Connected Layer\n",
    "in_features = resnet.fc.in_features\n",
    "\n",
    "# Replacing the Last Fully Connected Layer\n",
    "fc = nn.Linear(in_features=in_features, out_features=len(classes4))\n",
    "# fc = nn.Linear(in_features=in_features, out_features=1)\n",
    "resnet.fc = fc\n",
    "\n",
    "\n",
    "# Updating the Weights and Bias of the last layer\n",
    "params_to_update = []\n",
    "for name, param in resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 25\n",
    "num_epoch = 20\n",
    "\n",
    "resnet, train_losses2, val_losses2 = train(\n",
    "    model=resnet,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader4,\n",
    "    test_dataloader=val_dataloader4,\n",
    "    print_every=print_every,\n",
    "    num_epoch=num_epoch\n",
    ")\n",
    "\n",
    "\n",
    "plt.plot(train_losses4, label='Training loss')\n",
    "plt.plot(val_losses4, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'tempo_and_pitch_shifted_final_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.load_state_dict(torch.load('tempo_and_pitch_shifted_final_state_dict', weights_only=True))\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = [\"deepfake\", \"human\"]\n",
    "\n",
    "y_test = []\n",
    "y_pred = []\n",
    "for img, label in test_subset4:\n",
    "    img = torch.Tensor(img)\n",
    "    img = img.to(device)\n",
    "    resnet.eval()\n",
    "    prediction = resnet(img[None])\n",
    "    \n",
    "    final_pred = classes4[torch.max(prediction, dim=1)[1]]\n",
    "    # final_pred = torch.max(prediction, dim=1)[1]\n",
    "\n",
    "    print(classes4[label], final_pred)\n",
    "    \n",
    "    y_test.append(classes4[label])\n",
    "    y_pred.append(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",(100*(np.array(y_test) == np.array(y_pred)).sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_pred, pos_label=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[\"deepfake\", \"human\"])\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[\"deepfake\", \"human\"])\n",
    "cmd.plot()\n",
    "plt.show()\n",
    "\n",
    "print(\"True Negative: \", tn, end= '\\t|\\t')\n",
    "print(\"False Positive: \", fp)\n",
    "print(\"-\" * 55)\n",
    "print(\"False Negative: \", fn, end='\\t|\\t')\n",
    "print(\"True Positive: \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = tp / (tp + fn)\n",
    "FPR = fp / (fp + tn)\n",
    "PPV = tp / (tp + fp)\n",
    "Specificity = tn / (fp + tn)\n",
    "\n",
    "print(TPR) # True Positive Rate / recall / sensitivity\n",
    "print(FPR) # False Positive Rate / fall-out\n",
    "print(PPV) # Positive Predictive Value / Precision\n",
    "print(Specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
